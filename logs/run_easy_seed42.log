Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 3, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.checkpoint_path)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(42)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1309, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
Loaded model and optimizer checkpoint from checkpoints/RR/easy/epoch100_top5_acc_0.6762_42.pt
Resuming from epoch 100
Top-1 ACC: 0.6424
Top-3 ACC: 0.6692
Top-5 ACC: 0.6762
Top-10 ACC: 0.6909
Micro Recall: 0.8348
Macro Recall: 0.8319
[ epoch 101/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 41/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 42/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 46/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 47/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 48/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 102/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 54/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 55/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 56/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 57/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 104/1000 | batch 1/75 ] Total Loss : 0.0004[ epoch 104/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 3/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 4/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 75/75 ] Total Loss : 0.0007
 Valid_multi | Epoch: 105 | Top-1 ACC: 0.6641 | Top-3 ACC: 0.6908 | Top-5 ACC: 0.7023 | Top-10 ACC: 0.7168 

 Valid Recall | Epoch: 105 | Micro_Recall: 0.7224 | Macro_Recall: 0.7239 
Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 413, in <module>
    main()
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 275, in main
    results_list_of_dics.extend(batch_results)
    ^^^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'results_list_of_dics' where it is not associated with a value
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.checkpoint_path)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(42)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1309, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
Loaded model and optimizer checkpoint from checkpoints/RR/easy/epoch100_top5_acc_0.6762_42.pt
Resuming from epoch 100
Top-1 ACC: 0.6424
Top-3 ACC: 0.6692
Top-5 ACC: 0.6762
Top-10 ACC: 0.6909
Micro Recall: 0.8348
Macro Recall: 0.8319
[ epoch 101/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 41/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 42/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 46/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 47/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 48/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 102/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 46/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 48/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 54/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 55/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 56/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 57/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 104/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 104/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 3/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 4/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 75/75 ] Total Loss : 0.0007
 Valid_multi | Epoch: 105 | Top-1 ACC: 0.6612 | Top-3 ACC: 0.6879 | Top-5 ACC: 0.7003 | Top-10 ACC: 0.7151 

 Valid Recall | Epoch: 105 | Micro_Recall: 0.7202 | Macro_Recall: 0.7207 

 Test_multi | Epoch: 105 | Top-1 ACC: 0.6262 | Top-3 ACC: 0.6527 | Top-5 ACC: 0.6641 | Top-10 ACC: 0.6764 

 Test Recall | Epoch: 105 | Micro_Recall: 0.8357 | Macro_Recall: 0.8341 
[ epoch 106/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 4/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 6/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 107/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 108/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 108/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 110/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 110/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 110 | Top-1 ACC: 0.6608 | Top-3 ACC: 0.6933 | Top-5 ACC: 0.7023 | Top-10 ACC: 0.7159 

 Valid Recall | Epoch: 110 | Micro_Recall: 0.7182 | Macro_Recall: 0.7176 

 Test_multi | Epoch: 110 | Top-1 ACC: 0.6423 | Top-3 ACC: 0.6660 | Top-5 ACC: 0.6761 | Top-10 ACC: 0.6828 

 Test Recall | Epoch: 110 | Micro_Recall: 0.8289 | Macro_Recall: 0.8290 
[ epoch 111/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 111/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 3/75 ] Total Loss : 0.0004[ epoch 111/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 112/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 113/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 115/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 115 | Top-1 ACC: 0.6521 | Top-3 ACC: 0.6793 | Top-5 ACC: 0.6875 | Top-10 ACC: 0.6974 

 Valid Recall | Epoch: 115 | Micro_Recall: 0.7163 | Macro_Recall: 0.7161 
[ epoch 116/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 118/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 120 | Top-1 ACC: 0.6394 | Top-3 ACC: 0.6785 | Top-5 ACC: 0.6900 | Top-10 ACC: 0.7081 

 Valid Recall | Epoch: 120 | Micro_Recall: 0.7817 | Macro_Recall: 0.7878 
[ epoch 121/1000 | batch 0/75 ] Total Loss : 0.0009[ epoch 121/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 121/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 121/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 122/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 122/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 123/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 123/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 125 | Top-1 ACC: 0.6492 | Top-3 ACC: 0.6945 | Top-5 ACC: 0.7102 | Top-10 ACC: 0.7221 

 Valid Recall | Epoch: 125 | Micro_Recall: 0.7907 | Macro_Recall: 0.7966 

 Test_multi | Epoch: 125 | Top-1 ACC: 0.6279 | Top-3 ACC: 0.6593 | Top-5 ACC: 0.6677 | Top-10 ACC: 0.6815 

 Test Recall | Epoch: 125 | Micro_Recall: 0.8103 | Macro_Recall: 0.8124 
[ epoch 126/1000 | batch 0/75 ] Total Loss : 0.0008[ epoch 126/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 126/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 126/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 126/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 126/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 130/1000 | batch 1/75 ] Total Loss : 0.0004[ epoch 130/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 130 | Top-1 ACC: 0.6459 | Top-3 ACC: 0.6735 | Top-5 ACC: 0.6842 | Top-10 ACC: 0.6929 

 Valid Recall | Epoch: 130 | Micro_Recall: 0.7048 | Macro_Recall: 0.7063 
[ epoch 131/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 36/75 ] Total Loss : 0.0006/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.checkpoint_path)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(42)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1309, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
Loaded model and optimizer checkpoint from checkpoints/RR/easy/epoch100_top5_acc_0.6762_42.pt
Resuming from epoch 100
Top-1 ACC: 0.6424
Top-3 ACC: 0.6692
Top-5 ACC: 0.6762
Top-10 ACC: 0.6909
Micro Recall: 0.8348
Macro Recall: 0.8319
[ epoch 101/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 41/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 42/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 46/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 47/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 48/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 101/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 101/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 102/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 38/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 39/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 40/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 102/1000 | batch 42/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 45/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 46/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 47/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 48/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 49/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 50/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 51/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 52/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 53/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 54/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 55/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 56/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 57/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 58/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 59/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 60/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 61/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 62/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 63/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 64/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 102/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 103/1000 | batch 68/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 103/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 104/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 104/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 104/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 104/1000 | batch 75/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 3/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 4/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 43/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 44/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 65/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 66/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 67/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 105/1000 | batch 69/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 70/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 71/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 72/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 73/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 74/75 ] Total Loss : 0.0007[ epoch 105/1000 | batch 75/75 ] Total Loss : 0.0007
 Valid_multi | Epoch: 105 | Top-1 ACC: 0.6608 | Top-3 ACC: 0.6859 | Top-5 ACC: 0.6974 | Top-10 ACC: 0.7131 

 Valid Recall | Epoch: 105 | Micro_Recall: 0.7198 | Macro_Recall: 0.7210 

 Test_multi | Epoch: 105 | Top-1 ACC: 0.6279 | Top-3 ACC: 0.6527 | Top-5 ACC: 0.6657 | Top-10 ACC: 0.6788 

 Test Recall | Epoch: 105 | Micro_Recall: 0.8369 | Macro_Recall: 0.8359 
[ epoch 106/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 4/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 6/75 ] Total Loss : 0.0007[ epoch 106/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 106/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 107/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 107/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 107/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 108/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 108/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 108/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 109/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 110/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 5/75 ] Total Loss : 0.0007[ epoch 110/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 110/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 110 | Top-1 ACC: 0.6690 | Top-3 ACC: 0.7019 | Top-5 ACC: 0.7143 | Top-10 ACC: 0.7254 

 Valid Recall | Epoch: 110 | Micro_Recall: 0.7273 | Macro_Recall: 0.7270 

 Test_multi | Epoch: 110 | Top-1 ACC: 0.6441 | Top-3 ACC: 0.6645 | Top-5 ACC: 0.6759 | Top-10 ACC: 0.6852 

 Test Recall | Epoch: 110 | Micro_Recall: 0.8269 | Macro_Recall: 0.8295 
[ epoch 111/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 111/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 111/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 111/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 112/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 112/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 113/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 113/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 114/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 114/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 115/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 115/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 115/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 115 | Top-1 ACC: 0.6492 | Top-3 ACC: 0.6748 | Top-5 ACC: 0.6842 | Top-10 ACC: 0.6953 

 Valid Recall | Epoch: 115 | Micro_Recall: 0.7156 | Macro_Recall: 0.7170 
[ epoch 116/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 116/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 116/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 117/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 118/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 118/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 118/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 119/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 119/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 120/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 120/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 120 | Top-1 ACC: 0.6373 | Top-3 ACC: 0.6789 | Top-5 ACC: 0.6908 | Top-10 ACC: 0.7036 

 Valid Recall | Epoch: 120 | Micro_Recall: 0.7813 | Macro_Recall: 0.7874 
[ epoch 121/1000 | batch 0/75 ] Total Loss : 0.0009[ epoch 121/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 121/1000 | batch 2/75 ] Total Loss : 0.0007[ epoch 121/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 121/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 122/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 122/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 122/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 123/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 123/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 123/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 124/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 124/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 125/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 125/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 125 | Top-1 ACC: 0.6488 | Top-3 ACC: 0.6974 | Top-5 ACC: 0.7126 | Top-10 ACC: 0.7246 

 Valid Recall | Epoch: 125 | Micro_Recall: 0.7931 | Macro_Recall: 0.7991 
[ epoch 126/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 126/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 126/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 127/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 127/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 128/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 128/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 0/75 ] Total Loss : 0.0003[ epoch 129/1000 | batch 1/75 ] Total Loss : 0.0004[ epoch 129/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 129/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 129/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 130/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 130/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 130/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 130 | Top-1 ACC: 0.6422 | Top-3 ACC: 0.6859 | Top-5 ACC: 0.6933 | Top-10 ACC: 0.7052 

 Valid Recall | Epoch: 130 | Micro_Recall: 0.7832 | Macro_Recall: 0.7883 
[ epoch 131/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 131/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 131/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 1/75 ] Total Loss : 0.0007[ epoch 132/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 132/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 132/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 133/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 133/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 133/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 134/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 134/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 135/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 135/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 135 | Top-1 ACC: 0.6616 | Top-3 ACC: 0.7028 | Top-5 ACC: 0.7106 | Top-10 ACC: 0.7196 

 Valid Recall | Epoch: 135 | Micro_Recall: 0.7937 | Macro_Recall: 0.8018 
[ epoch 136/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 136/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 136/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 0/75 ] Total Loss : 0.0003[ epoch 137/1000 | batch 1/75 ] Total Loss : 0.0004[ epoch 137/1000 | batch 2/75 ] Total Loss : 0.0004[ epoch 137/1000 | batch 3/75 ] Total Loss : 0.0004[ epoch 137/1000 | batch 4/75 ] Total Loss : 0.0004[ epoch 137/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 137/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 137/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 138/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 138/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 139/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 139/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 2/75 ] Total Loss : 0.0004[ epoch 140/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 140/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 140/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 140 | Top-1 ACC: 0.6513 | Top-3 ACC: 0.6863 | Top-5 ACC: 0.7036 | Top-10 ACC: 0.7172 

 Valid Recall | Epoch: 140 | Micro_Recall: 0.7789 | Macro_Recall: 0.7832 
[ epoch 141/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 42/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 43/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 44/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 45/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 46/75 ] Total Loss : 0.0005[ epoch 141/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 141/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 142/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 142/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 0/75 ] Total Loss : 0.0007[ epoch 143/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 143/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 144/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 42/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 43/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 44/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 45/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 46/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 47/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 48/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 49/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 50/75 ] Total Loss : 0.0005[ epoch 144/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 144/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 0/75 ] Total Loss : 0.0004[ epoch 145/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 7/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 8/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 9/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 145/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 145/1000 | batch 75/75 ] Total Loss : 0.0006
 Valid_multi | Epoch: 145 | Top-1 ACC: 0.6492 | Top-3 ACC: 0.6789 | Top-5 ACC: 0.6933 | Top-10 ACC: 0.7003 

 Valid Recall | Epoch: 145 | Micro_Recall: 0.7001 | Macro_Recall: 0.6943 
[ epoch 146/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 146/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 146/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 1/75 ] Total Loss : 0.0004[ epoch 147/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 4/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 5/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 6/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 147/1000 | batch 10/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 11/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 12/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 13/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 14/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 15/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 16/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 19/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 20/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 21/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 22/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 23/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 24/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 25/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 26/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 27/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 28/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 29/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 30/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 31/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 32/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 33/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 34/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 35/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 36/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 37/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 38/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 39/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 40/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 41/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 42/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 43/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 44/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 46/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 47/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 48/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 147/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 0/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 1/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 2/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 3/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 42/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 43/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 44/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 45/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 46/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 47/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 48/75 ] Total Loss : 0.0005[ epoch 148/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 148/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 17/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 18/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 42/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 43/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 44/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 45/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 46/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 47/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 48/75 ] Total Loss : 0.0005[ epoch 149/1000 | batch 49/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 50/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 51/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 149/1000 | batch 75/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 0/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 1/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 2/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 3/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 4/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 5/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 6/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 7/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 8/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 9/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 10/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 11/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 12/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 13/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 14/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 15/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 16/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 17/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 18/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 19/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 20/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 21/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 22/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 23/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 24/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 25/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 26/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 27/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 28/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 29/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 30/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 31/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 32/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 33/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 34/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 35/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 36/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 37/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 38/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 39/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 40/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 41/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 42/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 43/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 44/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 45/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 46/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 47/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 48/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 49/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 50/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 51/75 ] Total Loss : 0.0005[ epoch 150/1000 | batch 52/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 53/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 54/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 55/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 56/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 57/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 58/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 59/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 60/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 61/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 62/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 63/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 64/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 65/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 66/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 67/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 68/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 69/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 70/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 71/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 72/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 73/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 74/75 ] Total Loss : 0.0006[ epoch 150/1000 | batch 75/75 ] Total Loss : 0.0006/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.checkpoint_path)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(42)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1309, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 413, in <module>
    main()
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 109, in main
    checkpoint = torch.load(args.checkpoint_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 1327, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/RR/easy/epoch100_top5_acc_0.6762_42.pt'
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.checkpoint_path)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(42)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1309, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
Traceback (most recent call last):
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 414, in <module>
    main()
  File "/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py", line 109, in main
    checkpoint = torch.load(args.checkpoint_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 1327, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/miniconda3/envs/retrieval-retro/lib/python3.12/site-packages/torch/serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/RR/easy/epoch100_top5_acc_0.6762_42.pt'
