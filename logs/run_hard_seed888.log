/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_train_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  valid_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_valid_final_mpc_nre_K_3.pt', map_location=device)
/home/paperspace/Retrieval-Retro/main_Retrieval_Retro.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_dataset = torch.load(f'./dataset/our/{args.difficulty}/year_test_final_mpc_nre_K_3.pt', map_location=device)
configuration: K(3)_loss(bce)_retrieval(ours)_split(year)_seed(888)_gnn(GraphNetwork)_lr(0.0001)_batch_size(128)_embedder(Retrieval_Retro)_
cuda:0
Dataset Loaded!
Retrieval_Retro(
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=768, out_features=1142, bias=True)
    (3): Sigmoid()
  )
  (gnn): GraphNetwork(
    (GN_encoder): Encoder(
      (node_encoder): Sequential(
        (0): Linear(in_features=200, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (edge_encoder): Sequential(
        (0): Linear(in_features=400, out_features=256, bias=True)
        (1): PReLU(num_parameters=1)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (stacked_processor): ModuleList(
      (0-2): 3 x Processor(
        (edge_model): EdgeModel(
          (edge_mlp): Sequential(
            (0): Linear(in_features=768, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
        (node_model): NodeModel(
          (node_mlp_1): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
          (node_mlp_2): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (2): PReLU(num_parameters=1)
            (3): Linear(in_features=512, out_features=256, bias=True)
          )
        )
      )
    )
  )
  (self_attention): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
  (self_attention_2): Self_TransformerEncoder_non(
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention_sa_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (cross_attention_2): Cross_TransformerEncoder_non(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention_non()
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (layer_norms): ModuleList(
          (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (fusion_linear_2): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): PReLU(num_parameters=1)
  )
)
No checkpoint path provided
[ epoch 1/1000 | batch 0/23 ] Total Loss : 0.7815[ epoch 1/1000 | batch 1/23 ] Total Loss : 0.7345[ epoch 1/1000 | batch 2/23 ] Total Loss : 0.7022[ epoch 1/1000 | batch 3/23 ] Total Loss : 0.6771[ epoch 1/1000 | batch 4/23 ] Total Loss : 0.6555[ epoch 1/1000 | batch 5/23 ] Total Loss : 0.6359[ epoch 1/1000 | batch 6/23 ] Total Loss : 0.6176[ epoch 1/1000 | batch 7/23 ] Total Loss : 0.6001[ epoch 1/1000 | batch 8/23 ] Total Loss : 0.5830[ epoch 1/1000 | batch 9/23 ] Total Loss : 0.5664[ epoch 1/1000 | batch 10/23 ] Total Loss : 0.5500[ epoch 1/1000 | batch 11/23 ] Total Loss : 0.5337[ epoch 1/1000 | batch 12/23 ] Total Loss : 0.5177[ epoch 1/1000 | batch 13/23 ] Total Loss : 0.5018[ epoch 1/1000 | batch 14/23 ] Total Loss : 0.4862[ epoch 1/1000 | batch 15/23 ] Total Loss : 0.4707[ epoch 1/1000 | batch 16/23 ] Total Loss : 0.4555[ epoch 1/1000 | batch 17/23 ] Total Loss : 0.4406[ epoch 1/1000 | batch 18/23 ] Total Loss : 0.4261[ epoch 1/1000 | batch 19/23 ] Total Loss : 0.4119[ epoch 1/1000 | batch 20/23 ] Total Loss : 0.3982[ epoch 1/1000 | batch 21/23 ] Total Loss : 0.3849[ epoch 1/1000 | batch 22/23 ] Total Loss : 0.3720[ epoch 1/1000 | batch 23/23 ] Total Loss : 0.3597[ epoch 2/1000 | batch 0/23 ] Total Loss : 0.0646[ epoch 2/1000 | batch 1/23 ] Total Loss : 0.0600[ epoch 2/1000 | batch 2/23 ] Total Loss : 0.0553[ epoch 2/1000 | batch 3/23 ] Total Loss : 0.0514[ epoch 2/1000 | batch 4/23 ] Total Loss : 0.0479[ epoch 2/1000 | batch 5/23 ] Total Loss : 0.0448[ epoch 2/1000 | batch 6/23 ] Total Loss : 0.0421[ epoch 2/1000 | batch 7/23 ] Total Loss : 0.0398[ epoch 2/1000 | batch 8/23 ] Total Loss : 0.0378[ epoch 2/1000 | batch 9/23 ] Total Loss : 0.0360[ epoch 2/1000 | batch 10/23 ] Total Loss : 0.0344[ epoch 2/1000 | batch 11/23 ] Total Loss : 0.0330[ epoch 2/1000 | batch 12/23 ] Total Loss : 0.0318[ epoch 2/1000 | batch 13/23 ] Total Loss : 0.0307[ epoch 2/1000 | batch 14/23 ] Total Loss : 0.0297[ epoch 2/1000 | batch 15/23 ] Total Loss : 0.0288[ epoch 2/1000 | batch 16/23 ] Total Loss : 0.0280[ epoch 2/1000 | batch 17/23 ] Total Loss : 0.0272[ epoch 2/1000 | batch 18/23 ] Total Loss : 0.0266[ epoch 2/1000 | batch 19/23 ] Total Loss : 0.0260[ epoch 2/1000 | batch 20/23 ] Total Loss : 0.0254[ epoch 2/1000 | batch 21/23 ] Total Loss : 0.0249[ epoch 2/1000 | batch 22/23 ] Total Loss : 0.0245[ epoch 2/1000 | batch 23/23 ] Total Loss : 0.0241[ epoch 3/1000 | batch 0/23 ] Total Loss : 0.0134[ epoch 3/1000 | batch 1/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 2/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 3/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 4/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 5/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 6/23 ] Total Loss : 0.0137[ epoch 3/1000 | batch 7/23 ] Total Loss : 0.0136[ epoch 3/1000 | batch 8/23 ] Total Loss : 0.0136[ epoch 3/1000 | batch 9/23 ] Total Loss : 0.0135[ epoch 3/1000 | batch 10/23 ] Total Loss : 0.0135[ epoch 3/1000 | batch 11/23 ] Total Loss : 0.0135[ epoch 3/1000 | batch 12/23 ] Total Loss : 0.0135[ epoch 3/1000 | batch 13/23 ] Total Loss : 0.0135[ epoch 3/1000 | batch 14/23 ] Total Loss : 0.0134[ epoch 3/1000 | batch 15/23 ] Total Loss : 0.0134[ epoch 3/1000 | batch 16/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 17/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 18/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 19/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 20/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 21/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 22/23 ] Total Loss : 0.0133[ epoch 3/1000 | batch 23/23 ] Total Loss : 0.0133[ epoch 4/1000 | batch 0/23 ] Total Loss : 0.0132[ epoch 4/1000 | batch 1/23 ] Total Loss : 0.0129[ epoch 4/1000 | batch 2/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 3/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 4/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 5/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 6/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 7/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 8/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 9/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 10/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 11/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 12/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 13/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 14/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 15/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 16/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 17/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 18/23 ] Total Loss : 0.0127[ epoch 4/1000 | batch 19/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 20/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 21/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 22/23 ] Total Loss : 0.0128[ epoch 4/1000 | batch 23/23 ] Total Loss : 0.0128[ epoch 5/1000 | batch 0/23 ] Total Loss : 0.0131[ epoch 5/1000 | batch 1/23 ] Total Loss : 0.0130[ epoch 5/1000 | batch 2/23 ] Total Loss : 0.0129[ epoch 5/1000 | batch 3/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 4/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 5/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 6/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 7/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 8/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 9/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 10/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 11/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 12/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 13/23 ] Total Loss : 0.0127[ epoch 5/1000 | batch 14/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 15/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 16/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 17/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 18/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 19/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 20/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 21/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 22/23 ] Total Loss : 0.0126[ epoch 5/1000 | batch 23/23 ] Total Loss : 0.0126
 Valid_multi | Epoch: 5 | Top-1 ACC: 0.0000 | Top-3 ACC: 0.0000 | Top-5 ACC: 0.0000 | Top-10 ACC: 0.0000 

 Valid Recall | Epoch: 5 | Micro_Recall: 0.0000 | Macro_Recall: 0.0000 
[ epoch 6/1000 | batch 0/23 ] Total Loss : 0.0128[ epoch 6/1000 | batch 1/23 ] Total Loss : 0.0126[ epoch 6/1000 | batch 2/23 ] Total Loss : 0.0126[ epoch 6/1000 | batch 3/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 4/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 5/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 6/23 ] Total Loss : 0.0124[ epoch 6/1000 | batch 7/23 ] Total Loss : 0.0123[ epoch 6/1000 | batch 8/23 ] Total Loss : 0.0124[ epoch 6/1000 | batch 9/23 ] Total Loss : 0.0124[ epoch 6/1000 | batch 10/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 11/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 12/23 ] Total Loss : 0.0124[ epoch 6/1000 | batch 13/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 14/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 15/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 16/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 17/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 18/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 19/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 20/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 21/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 22/23 ] Total Loss : 0.0125[ epoch 6/1000 | batch 23/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 0/23 ] Total Loss : 0.0120[ epoch 7/1000 | batch 1/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 2/23 ] Total Loss : 0.0123[ epoch 7/1000 | batch 3/23 ] Total Loss : 0.0124[ epoch 7/1000 | batch 4/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 5/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 6/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 7/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 8/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 9/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 10/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 11/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 12/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 13/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 14/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 15/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 16/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 17/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 18/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 19/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 20/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 21/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 22/23 ] Total Loss : 0.0125[ epoch 7/1000 | batch 23/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 0/23 ] Total Loss : 0.0131[ epoch 8/1000 | batch 1/23 ] Total Loss : 0.0127[ epoch 8/1000 | batch 2/23 ] Total Loss : 0.0129[ epoch 8/1000 | batch 3/23 ] Total Loss : 0.0127[ epoch 8/1000 | batch 4/23 ] Total Loss : 0.0126[ epoch 8/1000 | batch 5/23 ] Total Loss : 0.0126[ epoch 8/1000 | batch 6/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 7/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 8/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 9/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 10/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 11/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 12/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 13/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 14/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 15/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 16/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 17/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 18/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 19/23 ] Total Loss : 0.0125[ epoch 8/1000 | batch 20/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 21/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 22/23 ] Total Loss : 0.0124[ epoch 8/1000 | batch 23/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 0/23 ] Total Loss : 0.0128[ epoch 9/1000 | batch 1/23 ] Total Loss : 0.0127[ epoch 9/1000 | batch 2/23 ] Total Loss : 0.0127[ epoch 9/1000 | batch 3/23 ] Total Loss : 0.0126[ epoch 9/1000 | batch 4/23 ] Total Loss : 0.0126[ epoch 9/1000 | batch 5/23 ] Total Loss : 0.0127[ epoch 9/1000 | batch 6/23 ] Total Loss : 0.0126[ epoch 9/1000 | batch 7/23 ] Total Loss : 0.0126[ epoch 9/1000 | batch 8/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 9/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 10/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 11/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 12/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 13/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 14/23 ] Total Loss : 0.0125[ epoch 9/1000 | batch 15/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 16/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 17/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 18/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 19/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 20/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 21/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 22/23 ] Total Loss : 0.0124[ epoch 9/1000 | batch 23/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 0/23 ] Total Loss : 0.0127[ epoch 10/1000 | batch 1/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 2/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 4/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 6/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 7/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 8/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 9/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 10/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 11/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 12/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 13/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 14/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 15/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 16/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 17/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 18/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 10/1000 | batch 21/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 22/23 ] Total Loss : 0.0124[ epoch 10/1000 | batch 23/23 ] Total Loss : 0.0124
 Valid_multi | Epoch: 10 | Top-1 ACC: 0.0000 | Top-3 ACC: 0.0000 | Top-5 ACC: 0.0000 | Top-10 ACC: 0.0000 

 Valid Recall | Epoch: 10 | Micro_Recall: 0.0000 | Macro_Recall: 0.0000 
[ epoch 11/1000 | batch 0/23 ] Total Loss : 0.0122[ epoch 11/1000 | batch 1/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 2/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 4/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 6/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 7/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 8/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 9/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 10/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 11/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 12/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 13/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 14/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 15/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 16/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 17/23 ] Total Loss : 0.0124[ epoch 11/1000 | batch 18/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 21/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 22/23 ] Total Loss : 0.0123[ epoch 11/1000 | batch 23/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 0/23 ] Total Loss : 0.0118[ epoch 12/1000 | batch 1/23 ] Total Loss : 0.0122[ epoch 12/1000 | batch 2/23 ] Total Loss : 0.0122[ epoch 12/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 4/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 6/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 7/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 12/1000 | batch 9/23 ] Total Loss : 0.0122[ epoch 12/1000 | batch 10/23 ] Total Loss : 0.0122[ epoch 12/1000 | batch 11/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 12/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 13/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 14/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 15/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 16/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 17/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 18/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 21/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 22/23 ] Total Loss : 0.0123[ epoch 12/1000 | batch 23/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 0/23 ] Total Loss : 0.0121[ epoch 13/1000 | batch 1/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 2/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 4/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 6/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 7/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 13/1000 | batch 9/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 10/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 11/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 12/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 13/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 14/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 15/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 16/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 17/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 18/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 21/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 22/23 ] Total Loss : 0.0123[ epoch 13/1000 | batch 23/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 0/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 1/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 2/23 ] Total Loss : 0.0124[ epoch 14/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 4/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 6/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 7/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 9/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 10/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 11/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 12/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 13/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 14/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 15/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 16/23 ] Total Loss : 0.0122[ epoch 14/1000 | batch 17/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 18/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 21/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 22/23 ] Total Loss : 0.0123[ epoch 14/1000 | batch 23/23 ] Total Loss : 0.0123[ epoch 15/1000 | batch 0/23 ] Total Loss : 0.0127[ epoch 15/1000 | batch 1/23 ] Total Loss : 0.0126[ epoch 15/1000 | batch 2/23 ] Total Loss : 0.0125[ epoch 15/1000 | batch 3/23 ] Total Loss : 0.0124[ epoch 15/1000 | batch 4/23 ] Total Loss : 0.0123[ epoch 15/1000 | batch 5/23 ] Total Loss : 0.0123[ epoch 15/1000 | batch 6/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 7/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 9/23 ] Total Loss : 0.0121[ epoch 15/1000 | batch 10/23 ] Total Loss : 0.0121[ epoch 15/1000 | batch 11/23 ] Total Loss : 0.0121[ epoch 15/1000 | batch 12/23 ] Total Loss : 0.0121[ epoch 15/1000 | batch 13/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 14/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 15/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 16/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 17/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 18/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 19/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 20/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 21/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 22/23 ] Total Loss : 0.0122[ epoch 15/1000 | batch 23/23 ] Total Loss : 0.0122
 Valid_multi | Epoch: 15 | Top-1 ACC: 0.0000 | Top-3 ACC: 0.0000 | Top-5 ACC: 0.0000 | Top-10 ACC: 0.0000 

 Valid Recall | Epoch: 15 | Micro_Recall: 0.0000 | Macro_Recall: 0.0000 
[ epoch 16/1000 | batch 0/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 1/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 2/23 ] Total Loss : 0.0121[ epoch 16/1000 | batch 3/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 4/23 ] Total Loss : 0.0121[ epoch 16/1000 | batch 5/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 6/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 7/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 9/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 10/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 11/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 12/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 13/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 14/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 15/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 16/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 17/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 18/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 19/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 20/23 ] Total Loss : 0.0123[ epoch 16/1000 | batch 21/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 22/23 ] Total Loss : 0.0122[ epoch 16/1000 | batch 23/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 0/23 ] Total Loss : 0.0125[ epoch 17/1000 | batch 1/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 2/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 3/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 4/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 5/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 6/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 7/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 9/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 10/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 11/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 12/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 13/23 ] Total Loss : 0.0121[ epoch 17/1000 | batch 14/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 15/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 16/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 17/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 18/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 19/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 20/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 21/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 22/23 ] Total Loss : 0.0122[ epoch 17/1000 | batch 23/23 ] Total Loss : 0.0122[ epoch 18/1000 | batch 0/23 ] Total Loss : 0.0117[ epoch 18/1000 | batch 1/23 ] Total Loss : 0.0120[ epoch 18/1000 | batch 2/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 3/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 4/23 ] Total Loss : 0.0120[ epoch 18/1000 | batch 5/23 ] Total Loss : 0.0120[ epoch 18/1000 | batch 6/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 7/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 8/23 ] Total Loss : 0.0120[ epoch 18/1000 | batch 9/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 10/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 11/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 12/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 13/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 14/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 15/23 ] Total Loss : 0.0122[ epoch 18/1000 | batch 16/23 ] Total Loss : 0.0122[ epoch 18/1000 | batch 17/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 18/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 19/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 20/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 21/23 ] Total Loss : 0.0121[ epoch 18/1000 | batch 22/23 ] Total Loss : 0.0122[ epoch 18/1000 | batch 23/23 ] Total Loss : 0.0122[ epoch 19/1000 | batch 0/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 1/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 2/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 3/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 4/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 5/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 6/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 7/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 8/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 9/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 10/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 11/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 12/23 ] Total Loss : 0.0120[ epoch 19/1000 | batch 13/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 14/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 15/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 16/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 17/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 18/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 19/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 20/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 21/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 22/23 ] Total Loss : 0.0121[ epoch 19/1000 | batch 23/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 0/23 ] Total Loss : 0.0125[ epoch 20/1000 | batch 1/23 ] Total Loss : 0.0123[ epoch 20/1000 | batch 2/23 ] Total Loss : 0.0123[ epoch 20/1000 | batch 3/23 ] Total Loss : 0.0123[ epoch 20/1000 | batch 4/23 ] Total Loss : 0.0124[ epoch 20/1000 | batch 5/23 ] Total Loss : 0.0124[ epoch 20/1000 | batch 6/23 ] Total Loss : 0.0122[ epoch 20/1000 | batch 7/23 ] Total Loss : 0.0122[ epoch 20/1000 | batch 8/23 ] Total Loss : 0.0122[ epoch 20/1000 | batch 9/23 ] Total Loss : 0.0122[ epoch 20/1000 | batch 10/23 ] Total Loss : 0.0122[ epoch 20/1000 | batch 11/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 12/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 13/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 14/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 15/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 16/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 17/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 18/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 19/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 20/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 21/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 22/23 ] Total Loss : 0.0121[ epoch 20/1000 | batch 23/23 ] Total Loss : 0.0121
 Valid_multi | Epoch: 20 | Top-1 ACC: 0.0000 | Top-3 ACC: 0.0000 | Top-5 ACC: 0.0000 | Top-10 ACC: 0.0000 

 Valid Recall | Epoch: 20 | Micro_Recall: 0.0000 | Macro_Recall: 0.0000 
[ epoch 21/1000 | batch 0/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 1/23 ] Total Loss : 0.0118[ epoch 21/1000 | batch 2/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 3/23 ] Total Loss : 0.0120[ epoch 21/1000 | batch 4/23 ] Total Loss : 0.0120[ epoch 21/1000 | batch 5/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 6/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 7/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 8/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 9/23 ] Total Loss : 0.0122[ epoch 21/1000 | batch 10/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 11/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 12/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 13/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 14/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 15/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 16/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 17/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 18/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 19/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 20/23 ] Total Loss : 0.0121[ epoch 21/1000 | batch 21/23 ] Total Loss : 0.0120[ epoch 21/1000 | batch 22/23 ] Total Loss : 0.0120[ epoch 21/1000 | batch 23/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 0/23 ] Total Loss : 0.0122[ epoch 22/1000 | batch 1/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 2/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 3/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 4/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 5/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 6/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 7/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 8/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 9/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 10/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 11/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 12/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 13/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 14/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 15/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 16/23 ] Total Loss : 0.0120[ epoch 22/1000 | batch 17/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 18/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 19/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 20/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 21/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 22/23 ] Total Loss : 0.0119[ epoch 22/1000 | batch 23/23 ] Total Loss : 0.0120[ epoch 23/1000 | batch 0/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 1/23 ] Total Loss : 0.0117[ epoch 23/1000 | batch 2/23 ] Total Loss : 0.0117[ epoch 23/1000 | batch 3/23 ] Total Loss : 0.0120[ epoch 23/1000 | batch 4/23 ] Total Loss : 0.0119[ epoch 23/1000 | batch 5/23 ] Total Loss : 0.0119[ epoch 23/1000 | batch 6/23 ] Total Loss : 0.0119[ epoch 23/1000 | batch 7/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 8/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 9/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 10/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 11/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 12/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 13/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 14/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 15/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 16/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 17/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 18/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 19/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 20/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 21/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 22/23 ] Total Loss : 0.0118[ epoch 23/1000 | batch 23/23 ] Total Loss : 0.0118[ epoch 24/1000 | batch 0/23 ] Total Loss : 0.0119[ epoch 24/1000 | batch 1/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 2/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 3/23 ] Total Loss : 0.0118[ epoch 24/1000 | batch 4/23 ] Total Loss : 0.0118[ epoch 24/1000 | batch 5/23 ] Total Loss : 0.0118[ epoch 24/1000 | batch 6/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 7/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 8/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 9/23 ] Total Loss : 0.0118[ epoch 24/1000 | batch 10/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 11/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 12/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 13/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 14/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 15/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 16/23 ] Total Loss : 0.0117[ epoch 24/1000 | batch 17/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 18/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 19/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 20/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 21/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 22/23 ] Total Loss : 0.0116[ epoch 24/1000 | batch 23/23 ] Total Loss : 0.0116[ epoch 25/1000 | batch 0/23 ] Total Loss : 0.0115[ epoch 25/1000 | batch 1/23 ] Total Loss : 0.0118[ epoch 25/1000 | batch 2/23 ] Total Loss : 0.0115[ epoch 25/1000 | batch 3/23 ] Total Loss : 0.0113[ epoch 25/1000 | batch 4/23 ] Total Loss : 0.0113[ epoch 25/1000 | batch 5/23 ] Total Loss : 0.0113[ epoch 25/1000 | batch 6/23 ] Total Loss : 0.0113[ epoch 25/1000 | batch 7/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 8/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 9/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 10/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 11/23 ] Total Loss : 0.0115[ epoch 25/1000 | batch 12/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 13/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 14/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 15/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 16/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 17/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 18/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 19/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 20/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 21/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 22/23 ] Total Loss : 0.0114[ epoch 25/1000 | batch 23/23 ] Total Loss : 0.0114
 Valid_multi | Epoch: 25 | Top-1 ACC: 0.0000 | Top-3 ACC: 0.0000 | Top-5 ACC: 0.0000 | Top-10 ACC: 0.0000 

 Valid Recall | Epoch: 25 | Micro_Recall: 0.0000 | Macro_Recall: 0.0000 
[ epoch 26/1000 | batch 0/23 ] Total Loss : 0.0114[ epoch 26/1000 | batch 1/23 ] Total Loss : 0.0112[ epoch 26/1000 | batch 2/23 ] Total Loss : 0.0112[ epoch 26/1000 | batch 3/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 4/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 5/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 6/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 7/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 8/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 9/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 10/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 11/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 12/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 13/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 14/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 15/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 16/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 17/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 18/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 19/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 20/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 21/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 22/23 ] Total Loss : 0.0111[ epoch 26/1000 | batch 23/23 ] Total Loss : 0.0111[ epoch 27/1000 | batch 0/23 ] Total Loss : 0.0118[ epoch 27/1000 | batch 1/23 ] Total Loss : 0.0112[ epoch 27/1000 | batch 2/23 ] Total Loss : 0.0110[ epoch 27/1000 | batch 3/23 ] Total Loss : 0.0109[ epoch 27/1000 | batch 4/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 5/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 6/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 7/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 8/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 9/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 10/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 11/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 12/23 ] Total Loss : 0.0108[ epoch 27/1000 | batch 13/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 14/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 15/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 16/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 17/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 18/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 19/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 20/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 21/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 22/23 ] Total Loss : 0.0107[ epoch 27/1000 | batch 23/23 ] Total Loss : 0.0107[ epoch 28/1000 | batch 0/23 ] Total Loss : 0.0101[ epoch 28/1000 | batch 1/23 ] Total Loss : 0.0106[ epoch 28/1000 | batch 2/23 ] Total Loss : 0.0107[ epoch 28/1000 | batch 3/23 ] Total Loss : 0.0105[ epoch 28/1000 | batch 4/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 5/23 ] Total Loss : 0.0103[ epoch 28/1000 | batch 6/23 ] Total Loss : 0.0103[ epoch 28/1000 | batch 7/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 8/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 9/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 10/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 11/23 ] Total Loss : 0.0105[ epoch 28/1000 | batch 12/23 ] Total Loss : 0.0105[ epoch 28/1000 | batch 13/23 ] Total Loss : 0.0105[ epoch 28/1000 | batch 14/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 15/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 16/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 17/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 18/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 19/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 20/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 21/23 ] Total Loss : 0.0104[ epoch 28/1000 | batch 22/23 ] Total Loss : 0.0103[ epoch 28/1000 | batch 23/23 ] Total Loss : 0.0103[ epoch 29/1000 | batch 0/23 ] Total Loss : 0.0097[ epoch 29/1000 | batch 1/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 2/23 ] Total Loss : 0.0102[ epoch 29/1000 | batch 3/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 4/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 5/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 6/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 7/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 8/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 9/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 10/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 11/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 12/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 13/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 14/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 15/23 ] Total Loss : 0.0101[ epoch 29/1000 | batch 16/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 17/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 18/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 19/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 20/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 21/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 22/23 ] Total Loss : 0.0100[ epoch 29/1000 | batch 23/23 ] Total Loss : 0.0099[ epoch 30/1000 | batch 0/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 1/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 2/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 3/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 4/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 5/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 6/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 7/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 8/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 9/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 10/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 11/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 12/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 13/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 14/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 15/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 16/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 17/23 ] Total Loss : 0.0095[ epoch 30/1000 | batch 18/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 19/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 20/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 21/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 22/23 ] Total Loss : 0.0096[ epoch 30/1000 | batch 23/23 ] Total Loss : 0.0096
 Valid_multi | Epoch: 30 | Top-1 ACC: 0.0080 | Top-3 ACC: 0.0106 | Top-5 ACC: 0.0120 | Top-10 ACC: 0.0159 

 Valid Recall | Epoch: 30 | Micro_Recall: 0.0076 | Macro_Recall: 0.0076 

Evaluating on test set - New best accuracy

 Test_multi | Epoch: 30 | Top-1 ACC: 0.0052 | Top-3 ACC: 0.0114 | Top-5 ACC: 0.0135 | Top-10 ACC: 0.0142 

 Test Recall | Epoch: 30 | Micro_Recall: 0.0044 | Macro_Recall: 0.0044 
[ epoch 31/1000 | batch 0/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 1/23 ] Total Loss : 0.0091[ epoch 31/1000 | batch 2/23 ] Total Loss : 0.0093[ epoch 31/1000 | batch 3/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 4/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 5/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 6/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 7/23 ] Total Loss : 0.0093[ epoch 31/1000 | batch 8/23 ] Total Loss : 0.0093[ epoch 31/1000 | batch 9/23 ] Total Loss : 0.0093[ epoch 31/1000 | batch 10/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 11/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 12/23 ] Total Loss : 0.0093[ epoch 31/1000 | batch 13/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 14/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 15/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 16/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 17/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 18/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 19/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 20/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 21/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 22/23 ] Total Loss : 0.0092[ epoch 31/1000 | batch 23/23 ] Total Loss : 0.0092[ epoch 32/1000 | batch 0/23 ] Total Loss : 0.0085[ epoch 32/1000 | batch 1/23 ] Total Loss : 0.0087[ epoch 32/1000 | batch 2/23 ] Total Loss : 0.0087[ epoch 32/1000 | batch 3/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 4/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 5/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 6/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 7/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 8/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 9/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 10/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 11/23 ] Total Loss : 0.0090[ epoch 32/1000 | batch 12/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 13/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 14/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 15/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 16/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 17/23 ] Total Loss : 0.0089[ epoch 32/1000 | batch 18/23 ] Total Loss : 0.0088[ epoch 32/1000 | batch 19/23 ] Total Loss : 0.0088[ epoch 32/1000 | batch 20/23 ] Total Loss : 0.0088[ epoch 32/1000 | batch 21/23 ] Total Loss : 0.0088[ epoch 32/1000 | batch 22/23 ] Total Loss : 0.0088[ epoch 32/1000 | batch 23/23 ] Total Loss : 0.0088[ epoch 33/1000 | batch 0/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 1/23 ] Total Loss : 0.0090[ epoch 33/1000 | batch 2/23 ] Total Loss : 0.0087[ epoch 33/1000 | batch 3/23 ] Total Loss : 0.0087[ epoch 33/1000 | batch 4/23 ] Total Loss : 0.0087[ epoch 33/1000 | batch 5/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 6/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 7/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 8/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 9/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 10/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 11/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 12/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 13/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 14/23 ] Total Loss : 0.0085[ epoch 33/1000 | batch 15/23 ] Total Loss : 0.0086[ epoch 33/1000 | batch 16/23 ] Total Loss : 0.0085[ epoch 33/1000 | batch 17/23 ] Total Loss : 0.0085[ epoch 33/1000 | batch 18/23 ] Total Loss : 0.0084[ epoch 33/1000 | batch 19/23 ] Total Loss : 0.0084[ epoch 33/1000 | batch 20/23 ] Total Loss : 0.0084[ epoch 33/1000 | batch 21/23 ] Total Loss : 0.0084[ epoch 33/1000 | batch 22/23 ] Total Loss : 0.0085[ epoch 33/1000 | batch 23/23 ] Total Loss : 0.0084[ epoch 34/1000 | batch 0/23 ] Total Loss : 0.0077[ epoch 34/1000 | batch 1/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 2/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 3/23 ] Total Loss : 0.0083[ epoch 34/1000 | batch 4/23 ] Total Loss : 0.0083[ epoch 34/1000 | batch 5/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 6/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 7/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 8/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 9/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 10/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 11/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 12/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 13/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 14/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 15/23 ] Total Loss : 0.0082[ epoch 34/1000 | batch 16/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 17/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 18/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 19/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 20/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 21/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 22/23 ] Total Loss : 0.0081[ epoch 34/1000 | batch 23/23 ] Total Loss : 0.0081[ epoch 35/1000 | batch 0/23 ] Total Loss : 0.0085[ epoch 35/1000 | batch 1/23 ] Total Loss : 0.0081[ epoch 35/1000 | batch 2/23 ] Total Loss : 0.0080[ epoch 35/1000 | batch 3/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 4/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 5/23 ] Total Loss : 0.0077[ epoch 35/1000 | batch 6/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 7/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 8/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 9/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 10/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 11/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 12/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 13/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 14/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 15/23 ] Total Loss : 0.0079[ epoch 35/1000 | batch 16/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 17/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 18/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 19/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 20/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 21/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 22/23 ] Total Loss : 0.0078[ epoch 35/1000 | batch 23/23 ] Total Loss : 0.0078
 Valid_multi | Epoch: 35 | Top-1 ACC: 0.0385 | Top-3 ACC: 0.0398 | Top-5 ACC: 0.0425 | Top-10 ACC: 0.0465 

 Valid Recall | Epoch: 35 | Micro_Recall: 0.0367 | Macro_Recall: 0.0354 

Evaluating on test set - New best accuracy

 Test_multi | Epoch: 35 | Top-1 ACC: 0.0391 | Top-3 ACC: 0.0432 | Top-5 ACC: 0.0443 | Top-10 ACC: 0.0470 

 Test Recall | Epoch: 35 | Micro_Recall: 0.0335 | Macro_Recall: 0.0332 
[ epoch 36/1000 | batch 0/23 ] Total Loss : 0.0078[ epoch 36/1000 | batch 1/23 ] Total Loss : 0.0077[ epoch 36/1000 | batch 2/23 ] Total Loss : 0.0077[ epoch 36/1000 | batch 3/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 4/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 5/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 6/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 7/23 ] Total Loss : 0.0076[ epoch 36/1000 | batch 8/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 9/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 10/23 ] Total Loss : 0.0076[ epoch 36/1000 | batch 11/23 ] Total Loss : 0.0076[ epoch 36/1000 | batch 12/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 13/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 14/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 15/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 16/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 17/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 18/23 ] Total Loss : 0.0075[ epoch 36/1000 | batch 19/23 ] Total Loss : 0.0074[ epoch 36/1000 | batch 20/23 ] Total Loss : 0.0074[ epoch 36/1000 | batch 21/23 ] Total Loss : 0.0074[ epoch 36/1000 | batch 22/23 ] Total Loss : 0.0074[ epoch 36/1000 | batch 23/23 ] Total Loss : 0.0074[ epoch 37/1000 | batch 0/23 ] Total Loss : 0.0074[ epoch 37/1000 | batch 1/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 2/23 ] Total Loss : 0.0074[ epoch 37/1000 | batch 3/23 ] Total Loss : 0.0072[ epoch 37/1000 | batch 4/23 ] Total Loss : 0.0072[ epoch 37/1000 | batch 5/23 ] Total Loss : 0.0072[ epoch 37/1000 | batch 6/23 ] Total Loss : 0.0072[ epoch 37/1000 | batch 7/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 8/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 9/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 10/23 ] Total Loss : 0.0070[ epoch 37/1000 | batch 11/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 12/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 13/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 14/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 15/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 16/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 17/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 18/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 19/23 ] Total Loss : 0.0072[ epoch 37/1000 | batch 20/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 21/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 22/23 ] Total Loss : 0.0071[ epoch 37/1000 | batch 23/23 ] Total Loss : 0.0071[ epoch 38/1000 | batch 0/23 ] Total Loss : 0.0065[ epoch 38/1000 | batch 1/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 2/23 ] Total Loss : 0.0071[ epoch 38/1000 | batch 3/23 ] Total Loss : 0.0070[ epoch 38/1000 | batch 4/23 ] Total Loss : 0.0070[ epoch 38/1000 | batch 5/23 ] Total Loss : 0.0070[ epoch 38/1000 | batch 6/23 ] Total Loss : 0.0070[ epoch 38/1000 | batch 7/23 ] Total Loss : 0.0069[ epoch 38/1000 | batch 8/23 ] Total Loss : 0.0069[ epoch 38/1000 | batch 9/23 ] Total Loss : 0.0069[ epoch 38/1000 | batch 10/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 11/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 12/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 13/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 14/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 15/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 16/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 17/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 18/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 19/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 20/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 21/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 22/23 ] Total Loss : 0.0068[ epoch 38/1000 | batch 23/23 ] Total Loss : 0.0068[ epoch 39/1000 | batch 0/23 ] Total Loss : 0.0063[ epoch 39/1000 | batch 1/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 2/23 ] Total Loss : 0.0063[ epoch 39/1000 | batch 3/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 4/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 5/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 6/23 ] Total Loss : 0.0066[ epoch 39/1000 | batch 7/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 8/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 9/23 ] Total Loss : 0.0064[ epoch 39/1000 | batch 10/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 11/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 12/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 13/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 14/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 15/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 16/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 17/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 18/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 19/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 20/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 21/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 22/23 ] Total Loss : 0.0065[ epoch 39/1000 | batch 23/23 ] Total Loss : 0.0065[ epoch 40/1000 | batch 0/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 1/23 ] Total Loss : 0.0058[ epoch 40/1000 | batch 2/23 ] Total Loss : 0.0060[ epoch 40/1000 | batch 3/23 ] Total Loss : 0.0060[ epoch 40/1000 | batch 4/23 ] Total Loss : 0.0060[ epoch 40/1000 | batch 5/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 6/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 7/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 8/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 9/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 10/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 11/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 12/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 13/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 14/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 15/23 ] Total Loss : 0.0061[ epoch 40/1000 | batch 16/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 17/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 18/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 19/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 20/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 21/23 ] Total Loss : 0.0062[ epoch 40/1000 | batch 22/23 ] Total Loss : 0.0063[ epoch 40/1000 | batch 23/23 ] Total Loss : 0.0063
 Valid_multi | Epoch: 40 | Top-1 ACC: 0.0876 | Top-3 ACC: 0.0983 | Top-5 ACC: 0.0983 | Top-10 ACC: 0.0996 

 Valid Recall | Epoch: 40 | Micro_Recall: 0.0860 | Macro_Recall: 0.0834 

Evaluating on test set - New best accuracy

 Test_multi | Epoch: 40 | Top-1 ACC: 0.0899 | Top-3 ACC: 0.0972 | Top-5 ACC: 0.1013 | Top-10 ACC: 0.1044 

 Test Recall | Epoch: 40 | Micro_Recall: 0.0784 | Macro_Recall: 0.0793 
[ epoch 41/1000 | batch 0/23 ] Total Loss : 0.0062[ epoch 41/1000 | batch 1/23 ] Total Loss : 0.0063[ epoch 41/1000 | batch 2/23 ] Total Loss : 0.0063[ epoch 41/1000 | batch 3/23 ] Total Loss : 0.0062[ epoch 41/1000 | batch 4/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 5/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 6/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 7/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 8/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 9/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 10/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 11/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 12/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 13/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 14/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 15/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 16/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 17/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 18/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 19/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 20/23 ] Total Loss : 0.0061[ epoch 41/1000 | batch 21/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 22/23 ] Total Loss : 0.0060[ epoch 41/1000 | batch 23/23 ] Total Loss : 0.0060[ epoch 42/1000 | batch 0/23 ] Total Loss : 0.0051[ epoch 42/1000 | batch 1/23 ] Total Loss : 0.0052[ epoch 42/1000 | batch 2/23 ] Total Loss : 0.0052[ epoch 42/1000 | batch 3/23 ] Total Loss : 0.0054[ epoch 42/1000 | batch 4/23 ] Total Loss : 0.0055[ epoch 42/1000 | batch 5/23 ] Total Loss : 0.0055[ epoch 42/1000 | batch 6/23 ] Total Loss : 0.0056[ epoch 42/1000 | batch 7/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 8/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 9/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 10/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 11/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 12/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 13/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 14/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 15/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 16/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 17/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 18/23 ] Total Loss : 0.0057[ epoch 42/1000 | batch 19/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 20/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 21/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 22/23 ] Total Loss : 0.0058[ epoch 42/1000 | batch 23/23 ] Total Loss : 0.0058[ epoch 43/1000 | batch 0/23 ] Total Loss : 0.0060[ epoch 43/1000 | batch 1/23 ] Total Loss : 0.0060[ epoch 43/1000 | batch 2/23 ] Total Loss : 0.0061[ epoch 43/1000 | batch 3/23 ] Total Loss : 0.0061[ epoch 43/1000 | batch 4/23 ] Total Loss : 0.0060[ epoch 43/1000 | batch 5/23 ] Total Loss : 0.0059[ epoch 43/1000 | batch 6/23 ] Total Loss : 0.0058[ epoch 43/1000 | batch 7/23 ] Total Loss : 0.0058[ epoch 43/1000 | batch 8/23 ] Total Loss : 0.0058[ epoch 43/1000 | batch 9/23 ] Total Loss : 0.0057[ epoch 43/1000 | batch 10/23 ] Total Loss : 0.0057[ epoch 43/1000 | batch 11/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 12/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 13/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 14/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 15/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 16/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 17/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 18/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 19/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 20/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 21/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 22/23 ] Total Loss : 0.0056[ epoch 43/1000 | batch 23/23 ] Total Loss : 0.0056[ epoch 44/1000 | batch 0/23 ] Total Loss : 0.0050[ epoch 44/1000 | batch 1/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 2/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 3/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 4/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 5/23 ] Total Loss : 0.0055[ epoch 44/1000 | batch 6/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 7/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 8/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 9/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 10/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 11/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 12/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 13/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 14/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 15/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 16/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 17/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 18/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 19/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 20/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 21/23 ] Total Loss : 0.0053[ epoch 44/1000 | batch 22/23 ] Total Loss : 0.0054[ epoch 44/1000 | batch 23/23 ] Total Loss : 0.0054[ epoch 45/1000 | batch 0/23 ] Total Loss : 0.0054[ epoch 45/1000 | batch 1/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 2/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 3/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 4/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 5/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 6/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 7/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 8/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 9/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 10/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 11/23 ] Total Loss : 0.0050[ epoch 45/1000 | batch 12/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 13/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 14/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 15/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 16/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 17/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 18/23 ] Total Loss : 0.0051[ epoch 45/1000 | batch 19/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 20/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 21/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 22/23 ] Total Loss : 0.0052[ epoch 45/1000 | batch 23/23 ] Total Loss : 0.0052